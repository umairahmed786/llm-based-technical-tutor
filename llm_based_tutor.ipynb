{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8398f64-8de9-41d1-a001-9e36b4863e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import ipywidgets as widgets\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown, update_display, Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "873f954f-fd7d-468c-ae55-ddcd06391a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_GPT   = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "736c6053-0b66-4eeb-8fff-87f1b79709fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "openai = OpenAI()\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6117a32-5f96-44a9-9da4-260de8854cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an intelligent and patient technical tutor specialized in computer science, software engineering, and data science. \" \\\n",
    "\"Your goal is to explain technical concepts in a clear, concise, and engaging way â€” as if you are teaching a motivated student who is learning \" \\\n",
    "\"but may not yet be an expert. \" \\\n",
    "\"When the user asks a question:\\n\\n\" \\\n",
    "\"- Break it down step-by-step.\\n\" \\\n",
    "\"- Use simple examples or analogies if needed.\\n\" \\\n",
    "\"- Clarify jargon or advanced terms.\\n\" \\\n",
    "\"- If relevant, provide code snippets or diagrams in plain text.\\n\" \\\n",
    "\"- Be accurate and don't hallucinate â€” say \\\"I don't know\\\" if you're unsure.\\n\\n\" \\\n",
    "\"You are not just answering; you are teaching. Always aim to help the user truly understand the underlying concept.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5d5bebbc-adfa-4c06-8806-8b3f80147dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(question):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99c41266-0780-4cc3-8a1a-9f027ebccf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_response(messages, output_widget):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = MODEL_GPT,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        content = chunk.choices[0].delta.content or ''\n",
    "        content = content.replace(\"``\", \"\").replace(\"markdown\", \"\")\n",
    "        response += content\n",
    "        output_widget.value = f\"<b style='color:#1e8449;'>Tutor:</b> {response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb527bf6-84a1-4f00-a873-e96a15b56ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ollama_response(messages, output_widget):\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model = MODEL_LLAMA,\n",
    "        messages = messages,\n",
    "        stream = True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        content = chunk.choices[0].delta.content or ''\n",
    "        content = content.replace(\"``\", \"\").replace(\"markdown\", \"\")\n",
    "        response += content\n",
    "        output_widget.value = f\"<b style='color:#1e8449;'>Tutor:</b> {response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14ac911c-b574-4abe-a69c-4d1288f1142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = widgets.HTML(\"\"\"\n",
    "    <h2 style=\"text-align:center; color:#2e86de; font-family:'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\">\n",
    "        ðŸ¤– AI Tutor\n",
    "    </h2>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0fe2553e-e105-41f6-ba0d-bd879bccacc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_log = widgets.VBox()\n",
    "chat_scroll = widgets.Box([chat_log], layout=widgets.Layout(\n",
    "    border='1px solid #dcdcdc',\n",
    "    border_radius='8px',\n",
    "    height='400px',\n",
    "    overflow_y='auto',\n",
    "    padding='10px',\n",
    "    background_color='#fefefe',\n",
    "    box_shadow='0 2px 4px rgba(0,0,0,0.1)'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cce82283-16f0-45ff-8d95-a16fbdc15002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selector = widgets.Dropdown(\n",
    "    options=[('GPT', 'gpt'), ('Ollama', 'ollama')],\n",
    "    value='gpt',\n",
    "    description='Model:',\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "897ec691-5c43-4919-951e-5b7653fb539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_input = widgets.Textarea(\n",
    "    placeholder='Type your technical question here...',\n",
    "    layout=widgets.Layout(width='99.8%', height='70px', border='1px solid #ccc', border_radius='6px'),\n",
    "    style={\n",
    "        'description_width': 'initial',\n",
    "        'font_family': 'Segoe UI',\n",
    "        'font_size': '14px'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16e6e659-4be8-490c-b228-38f12844b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_button = widgets.Button(\n",
    "    description=\"Ask\",\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='100px', height='40px'),\n",
    "    style={\n",
    "        'button_color': '#2e86de',\n",
    "        'font_weight': 'bold',\n",
    "        'font_size': '14px',\n",
    "        'text_color': '#ffffff'\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5e37e408-f744-4c68-a9a3-7c28ded64f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c388e6cfd5cc4bb08b86c4472a17493a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n    <h2 style=\"text-align:center; color:#2e86de; font-family:\\'Segoe UI\\', Tahomaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "input_controls = widgets.HBox([model_selector, ask_button], layout=widgets.Layout(justify_content='space-between', margin='5px 0'))\n",
    "input_area = widgets.VBox([question_input, input_controls])\n",
    "\n",
    "\n",
    "ui_container = widgets.VBox([heading, chat_scroll, input_area])\n",
    "display(ui_container)\n",
    "\n",
    "\n",
    "def scroll_to_bottom():\n",
    "    display(Javascript(\"\"\"\n",
    "        const out = document.querySelectorAll('.output_subarea')[document.querySelectorAll('.output_subarea').length - 1];\n",
    "        if (out) out.scrollTop = out.scrollHeight;\n",
    "    \"\"\"))\n",
    "\n",
    "def on_submit(_):\n",
    "    question = question_input.value.strip()\n",
    "    if not question:\n",
    "        return\n",
    "    if question.lower() == 'exit':\n",
    "        chat_log.children += (widgets.HTML(\"<b>Goodbye! ðŸ‘‹</b>\"),)\n",
    "        return\n",
    "\n",
    "    question_input.value = \"\"  # Clear input\n",
    "    user_msg = widgets.HTML(f\"<b style='color:#2c3e50;'>You:</b> {question}\")\n",
    "    chat_log.children += (user_msg,)\n",
    "\n",
    "    messages = get_messages(question)\n",
    "    response_widget = widgets.HTML(value=\"<b style='color:#1e8449;'>Tutor:</b> \")\n",
    "    chat_log.children += (response_widget,)\n",
    "\n",
    "    scroll_to_bottom()\n",
    "\n",
    "    if model_selector.value == 'gpt':\n",
    "        get_gpt_response(messages, response_widget)\n",
    "    else:\n",
    "        get_ollama_response(messages, response_widget)\n",
    "\n",
    "ask_button.on_click(on_submit)\n",
    "\n",
    "\n",
    "def handle_enter(key):\n",
    "    if key['key'] == 'Enter' and not key['shiftKey']:\n",
    "        on_submit(None)\n",
    "        key['preventDefault']()\n",
    "\n",
    "question_input.on_msg(handle_enter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
